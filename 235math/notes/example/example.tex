\documentclass[11pt]{scrartcl}
\usepackage[sexy]{/home/gautierk/.config/evan}
\title{Linear Algebra}
\date{\today}
\author{Ze Dian Xiao}

\begin{document}
\maketitle
\clearpage
\tableofcontents
\clearpage

\begin{abstract}
	An important part of linear algebra is the study of vector spaces and the "homomorphisms" between them.
\end{abstract}
$\mathscr{Z}, \mathscr{Y}$
\section{Review Fields}
\begin{definition}
	A ring $R$ is a non-empty set with two binary operations $R$ x $R \rightarrow R$, $+$ addition and $\cdot$ multiplication satisfying
	\begin{enumerate}
		\ii
		$(a + b) + c = a + (b + c)$ Associativity of addition
		\ii
		$a + b = b + a$ Commutativity of addition
		\ii
		$\exists$ an element $0_R \in R$ such that $a \cdot 0_R = a \forall a \in R$
		$0_R$ is the neutral element of addition
		\ii
		$\forall a \in R$, there exists $b \in R$ such that $a + b = 0_R$, $b$ is called the additive inverse of $a$ and we write $b = (-a)$
		\ii
		$a \cdot (b \cdot c) = (a \cdot b) \cdot c$ Associativity of multiplication
		\ii
		There exists an element $1_R \in R$ such that $a \cdot 1_R = 1_R \cdot a = a, \forall a \in R$ $1_R$ is the identity of multiplication.
		\ii
		$a \cdot (b + c) = a \cdot b + a\cdot c$\\
		$(b + c ) \cdot a = b\cdot a + b\cdot c$\\
		$\forall a, b, c$ in $R$
	\end{enumerate}
\end{definition}
\begin{definition}
	A ring $R$ is said to be commutative if $a\cdot b = b\cdot a \forall a, b \in R$
\end{definition}
\begin{definition}
	A commutative R is said to be an integral domain if $\forall a,b \in R, a\cdot b = 0_R \implies a = 0_R$ or $b = 0_R$ (eg. $\ZZ$ is an integral domain)
\end{definition}
\begin{definition}
	A field is a commutative ring $R$ if $\forall a \in R, a \neq 0_R$, there exists $b \in R$ such that $ a\cdot b = b\cdot a = 1_R$.
\end{definition}
\begin{definition}
	A field F is an integral domain.\\
	Let $a, b \in F$ such that $a\cdot b = 0_F$\\
	If $b\neq 0$, there exists $y \in F$ such that $b\cdot y = 1_F$\\
	$a\cdot b = 0_F \implies$
	\begin{align*}
		a\cdot b\cdot y &= 0_F\\
		a\cdot(b\cdot y) &= 0_F\\
		a\cdot 1_F &= 0_F\\
		a &= 0_F
	\end{align*}
\end{definition}
\begin{example}[Example of Fields]
	$\ZZ_5, \RR, \QQ, \CC$
\end{example}
\begin{example}[Finite FIelds]
	$\ZZ_n$ is the ring of integers modulo $n$ with addition and multiplication modulo n.\\
	$\ZZ_4$ is the ring of integer $mod 4$\\
	$\ZZ_4 = \{0, 1_4, 2_4, 3_4\}$
\end{example}
\begin{proposition}[When is $\ZZ_n$ a field]
	$\ZZ_n$ is a field $\iff n$ is prime.\\
\end{proposition}
\begin{proof}
	Assume that $n$ is prime. Write $n = p$
	Let $a \in \ZZ_p$ such that $a \neq 0_P$, Let $X \in \ZZ$ such that $[x]_p = a$
	So $x \not\equiv 0 mod p,$ so $p$ does not divide $x$.
	Since $p$ is prime and $p$ does not divide $x$, then $gcd(p, x) = 1$.
	Then there exists $u, v \in \ZZ$ such that 
	\begin{align*}
		xu + pv &= 1\\
		xu &\equiv 1 \pmod p\\
		[xu]_p &= 1_p\\
		[x]_p[u]_p &= 1_p\\
		a\cdot [u]_p &= 1_p
	\end{align*}
	We prove tha tif $n$ is not prime, then $\ZZ_n$ is not a field, hence $\ZZ_4$ is not an integral domain(since $2_4 \cdot 2_4 = 0_4$) hence not a field. $\ZZ_6$ is not an integral domain(since $2_6\cdot 3_6 = 0_6$) hence not a field.
	If $n$ is not prime , there exists$x, y \in \ZZ$ such that 
	\[1 \leq x, y \lneq n, n = xy\]
	$xy \equiv 0$ mod $n$, so $[x]_n [y]_n = [0]_n$, $[x]_n \neq 0_n, [y]_n \neq 0_n$
	\begin{itemize}
		\ii
		A field $F$ is called finite if $|F| \lneq +\inf$
		\ii
		We will show that if $F$ is a finite field then $|F| = p^n$ for some prime $p$ and $n \in \NN$
		(No field with 6 elements, no field with 10 elements)
		\ii
		Conversely, for every prime $p$ and $n \in \NN$, there exists a finite field with $p^n$ elements (Not easy to show)
	\end{itemize}
	\[
	f(x) = x + y
	\]
\end{proof}
\begin{definition}[Complex Numbers]
		A complex number is an element of the form $a+ib$ where $a, b \in \ZZ$ and $i^2 = -1$\\
		The set of complex numbers is denoted by $\CC$\\
\end{definition}
\begin{example}
	Operation on complex numbers:
		\begin{align*}
			(a+ ib) + (c + id) &= (a + c) + i(b + d)\\
			(a +ib) \cdot (c + id) &= (ac + bd) + i(ad + bc)
		\end{align*}
\end{example}
\clearpage

IMPORTANT 

\[
f(x) = \frac{f(x) + f(-x)}{2} + \frac{f(x) - f(-x)}{2}
\]

Observe that the function $$f_e: x \rightarrow  \frac{f(x) + f(-x)}{2}$$ is even and $$f_o: x \rightarrow  \frac{f(x) - f(-x)}{2}$$ is odd

Suppose that 

\begin{theorem}
	Show that 
	\[
	det(C) = det(A)det(B)
	\]
\end{theorem}

\begin{proof}
	\begin{align*}
		det(C) = \sum_{\sigma \in S_{n+m}} c_{1, \sigma(1)}\cdots c_{n+m, \sigma(n+m)}
	\end{align*}
\end{proof}

\begin{definition}[Characteristic Polynomial]
	Let $A \in M_n(\FF)$ The characteristic polynomial $\Delta_A (x)$ is defined by $\Delta_A(x) = det(xI_n - A)$
	
	$\Delta_A$ has degree $n$
	
	\[
	\Delta_A(0) = det(-A) = (-1)^ndet(A) \text{ (constant term)}
	\]
	\[
	\Delta_A(0) \neq 0 \iff det(A) \neq 0 \iff \text{ A is invertible}
	\]
\end{definition}
\begin{example}
Let $A$ be an invertible $nxn$ matrix, Show that for all $t \neq 0$, 
\[
\Delta_A^{-1} (t) = \frac{t^n}{\Delta_A(0)}\Delta_A(\frac{1}{t})
\]
\end{example}

\begin{soln}
\begin{align*}
	\Delta_A^{-1} (t) &= det(tI_{nxn} - A^{-1})\\
	&= det(A^{-1}(tA - I_{nxn})\\
	&= det(tA^{-1}(A - \frac{1}{t}I_{nxn})\\
	&= det(-tA^{-1}(\frac{1}{t}I_{nxn}-A))\\
	&= det(-tA^{-1})det(\frac{1}{t}I_{nxn}-A)\\
	&= t^ndet(-A^{-1})det(\frac{1}{t}I_{nxn}-A)\\
	&= \frac{t^n}{\Delta_A(0)}\Delta_A(\frac{1}{t})
\end{align*}
\end{soln}

\begin{theorem}[Cailey-Hamilton Theorem]
	Let $A \in M_n(\FF)$ and $\Delta_A$ be the characteristic polynomial. Then the Cailey-Hamilton states that
	\[
	\Delta_A(A) = 0_{nxn}
	\]
	in the $n=2$ case,
	\[
	\Delta_A(A) = A^2 - (tr(A)A) + det(A) I_{nxn}
	\]
\end{theorem}

\begin{example}
	Let $A$ be and $nxn$ invertible matrix. Show that $A^{-1} = f(A)$ for some polynomial f of degree $n-1$ at most.
\end{example}

\begin{soln}
	Let 
	\[
	\Delta_A(x) = x^n + a_{n-1}x^{n-1} + \cdots + a_1x + a_0
	\]
	
	Given $A$ is invertible, $a_0 = \Delta_A(0) \neq 0$
	
	By Cailey-Hamilton, $\Delta_A(A) = 0_{nxn}$
	\begin{align*}
	A^n + a_{n-1}A^{n-1} + \cdots + a_1A + a_0I_{nxn} &= 0\\
	A^n + a_{n-1}A^{n-1} + \cdots + a_1A&= -a_0I_{nxn}\\
	A(A^{n-1} + a_{n-1}A^{n-2} + \cdots + a_1) &= -a_0I_{nxn}\\
	A\left\{\frac{-1}{a_0} (A^{n-1} + a_{n-1}A^{n-2} + \cdots + a_1I_{nxn}) \right\} &= I_{nxn}
	\end{align*}
	\[
	A^{-1} = -\frac{1}{a_0} (A^{n-1} + a_{n-1}A^{n-2} + \cdots + a_1I_{nxn}) = f(A)
	\]
	where $f(x) = -\frac{1}{a_0}(x^{n-1} + a_{n-1}x^{n-2} + \cdots + a_1)$
\end{soln}

\begin{example}
	Let $A$ be an $nxn$ matrix and $B$ be an $mxm$ matrix.
	\[
	C=
	\begin{bmatrix}
		A & X\\
		0 & B
	\end{bmatrix}
	\text{ where $X$ is $nxm$}
	\]
	
	Such that $det(C) = det(A)det(B)$
	
	It follows that:
	\begin{align*}
		det(C) = \sum_{\sigma \in S_{n+m}} sgn(\sigma) c_{1, \sigma(1)}\cdots c_{n+m, \sigma(n+m)}
	\end{align*}
	
	$c_{x1} = 0$ for $x \geq n+1$
	
	$c_{x2} = 0$ for $x \geq n+1$
	
	$c_{xn} = 0$ for $x \geq n+1$
	
	Pick a certain $x \geq n+1$ If $\sigma(x) \in \{1,\dots, b\}$, $c_{x,\sigma{x}} = 0$
	
	If $x \geq n+1$, $\sigma(x) \in \{n+1, \dots, n+m\}$
	If $1 \leq c \leq b$, $\sigma(x) \in \{1, \dots, n\}$
	
	\begin{align*}
		&=\sum_{\sigma_1, \sigma_2: \sigma_1 \in S_n, \sigma_2 \in S_{\{n+1, \dots, n+m\}}} sgn(\sigma_1 \sigma_2)  c_{1, \sigma_1(1)}\cdots c_{n, \sigma_1(n)} c_{n, \sigma_2(n+1)} \cdots c_{n+m, \sigma_2(n+m)} \\
		&\text{ define $\sigma = \sigma_1\sigma_2$}\\
		&= det(A)det(B)
	\end{align*}
\end{example}

\begin{theorem}
	\[
	det(AB) = det(A)det(B)
	\]
\end{theorem}

\begin{proof}
	\begin{align*}
		det(AB) &= \sum_{\sigma \in S_n} sgn(\sigma)(AB)_{1,\sigma(1)}\cdots(AB)_{n,\sigma(n)}\\
		&= \sum_{\sigma \in S_n} sgn(\sigma) 
	\end{align*}
\end{proof}


\begin{example}
	Extras Ex. 1 - Ex.3 Done!
\end{example}

\begin{definition}
	Let $A \in M_n(\FF)$ $\lambda$ is called an eigenvalue of $A$ if $\exists v \neq 0$ st $ Av = \lambda v$ is an eigenvector for the eigenvalue $\lambda$
\end{definition}

\begin{theorem}
	$\lambda$ is an eigenvalue of $A$ \emph{iff} $\Delta_A(\lambda) = 0$
\end{theorem}

\begin{example}[Extras II, Final 2018]
	Let $P$ be an $nxn$ matrix over $\FF$ such that $P^2 = P$
	\begin{enumerate}
		\ii
		Show that if $\lambda$ is an eigenvalue of $P$, then $\lambda \in \{0,1\}$
		\ii
		Show that $\FF^n = K_1 \oplus K_2$, where $K_1 = Null(P)$ and $K_2 = Ran(P)$
		\ii
		Show that $P$ is similar to a  diagonal matrix with entries 1 and 0's over the diagonal (Note: the diagonal contains all zeros or all 1s)
	\end{enumerate}
\end{example}

\begin{soln}
	\begin{enumerate}
    \ii[]
		\ii
		Let $\lambda$ is an eigenvalue of $P$. Then $\exists v \neq 0$ st $Pv = \lambda v \implies PPv = P(\lambda v) \implies P^2v = \lambda Pv = \lambda^2 v$
		
		Hence, $P^2v = \lambda^2 v$. $P^2 = P$ so $P^2v = Pv = \lambda v$, so $\lambda^2 v = \lambda v \implies (\lambda^2 -\lambda)v = 0$
		
		And so, 
		\[
		(\lambda^2 - \lambda) = 0 \implies \lambda^2 = \lambda \implies \lambda \in \{0,1\}
		\]
		\ii
		Show that 
		\[
		\FF^n = Ran(P) \oplus Null(P)
		\]
		Let $v \in \FF^n$ $v = v-Pv+Pv$. Where $Pv \in Ran(P)$ and $v-Pv \in Null(P)$.
		
		\[
		P(v-Pv) = Pv-P^2v = 0
		\]
		
		We have shown that $\FF^n = Ran(P) + Null(P)$
		
		To show $Ran(P) \cap Null(P) = \{0\}$, there are two approaches.
		\begin{itemize}
			\ii
			\[
			dim \FF^n = dim(Null(P) + Ran(P))
			\]
			
			From the dimension argument,
			\begin{align*}
			\underbrace{dim Null(P) + dim Ran(P)}_{n} - dim (Ran(P) \cap Null(P)) &= dim(Null(P) + Null(P))\\
			 \text{ from Rank-Nullity}\\
			dim (Ran(P) \cap Null(P)) &= n-n = 0\\
			\therefore Ran(P) \cap Null(P) &= \{0\}
			\end{align*}
			\ii
			Without dimension argument
			
			Let $v \in Ran(P) \cap Null(P)$, then $v \in Ran(P)$. Hence $\exists u \in \FF^n$ st $v = Pu$
			\begin{align*}
				Pv &= P^2u = Pu\\
				Pu &= v\\
				\therefore Pv &= v\\
			\end{align*}
			but also, $v \in Null(P)$, hence $Pv = 0 \implies v = 0$
		\end{itemize}
		\ii
		$\FF^n = Null(P) \oplus Ran(P)$. Let $v_1, \dots, v_k$ be a basis of $Null(P)$, and $v_{k+1}, \dots, v_{n}$ be a basis of $Ran(P)$.
		
		Then, 
		\[
		B = \{v_1, \dots, v_k, v_{k+1}, \dots, v_n\}
		\]
		is a basis of $\FF^n$. 
		\[
		Pv_1 = 0, Pv_{k+1} = v_{k+1} = 0v_1 + \dots + 1v_{k+1} + 0v_{k+2} + \dots + 0v_n
		\]
		
		\[
		\begin{bmatrix}
			0 & 0 & \dots & 0 & 0 & 0 & \dots & 0\\
			\vdots & \vdots & \ddots & \vdots & \vdots & \vdots & \ddots & \vdots\\
			0 & 0 & \dots & 0 & 1 & 0 & \dots & 0\\
			0 & 0 & \dots & 0 & 0 & 1 & \dots & 0\\
			\vdots & \vdots & \ddots & \vdots & \vdots & \vdots & \ddots & \vdots\\
			0 & 0 & \dots & 0 & 0 & 0 & \dots & 1\\
		\end{bmatrix}
		\]
		Two same representations of a matrix are similar
	\end{enumerate} 
\end{soln}

\begin{example}
	Find all eigenvalues and corresponding eigenspaces of the $nxn$ matrix of $\CC$
	\[
	A_n =
	\begin{bmatrix}
		0 & 1 & \dots & 1\\
		1 & 0 & \dots & 0\\
		\vdots & 0 & \ddots & 0\\
		1 & 0 & \dots & 0
	\end{bmatrix}
	\]
\end{example}

\begin{soln}
	Let $\lambda$ be an eigenvalue of $A_n$. Then there exists $v \in \CC^n$ non zero, such that $A_nv = \lambda v$.
	\[
	\begin{bmatrix}
	0 & 1 & \dots & 1\\
	1 & 0 & \dots & 0\\
	\vdots & 0 & \ddots & 0\\
	1 & 0 & \dots & 0
	\end{bmatrix}
	\begin{bmatrix}
	v_1\\
	\vdots\\
	\vdots\\
	v_n
	\end{bmatrix}
	= 
	\begin{bmatrix}
	\lambda v_1\\
	\vdots\\
	\vdots\\
	\lambda v_n
	\end{bmatrix}
	\]
	
	\begin{note*}
		Assume $A \in M_n(\FF)$ not invertible, then $A$ is not injective, then $Ker(A) \neq \{0\}$. Then there exists $v \neq 0$, st $Av = 0$. Then 0 is an eigenvalue of $A$.
	\end{note*}

	If $\lambda = 0$, then the first line becomes $v_2 + \dots + v_n = 0$. Second to last line we have $v_1 = 0$.
	
	Then the eigenspace attached to 0 is 
	\[
	E_0 = \{(v_1, \dots, v_n) \in \FF^n: v_1 = 0, v_2 + \dots + v_n =0\}
	\]
	where $dim(E_0) = n-2$
	
	If $\lambda \neq 0$, then the second to the last line are such that $v_2 = \dots = v_n = \frac{1v_1}{\lambda}$. Then plugging back into the first line we get that $v_2 + v_3 + \dots + v_n = \lambda v_1$
	
	\[
	\frac{n-1}{\lambda} v_1 = \lambda v_1
	\]
	
	If $v_1 = 0$, then it follows that $v_i = 0: i= 2, \dots, n$. But this does not respect the definition of an eigenspace.
	
	If $v_1 \neq 0 \implies \frac{n-1}{\lambda} = \lambda \implies \lambda^2 = n-1 \implies \lambda = \pm \sqrt{n-1}$
	\begin{note*}
	The field here is $\CC$ because in the case of another field, it could be that some eigenvalues do not exist.
	\end{note*}

	What is the eigenspace attached to $\sqrt{n-1}$
	\[
	E_{\sqrt{n-1}} = \{(v_1, \dots, v_n)\in \CC^n : v_2 = \dots = v_n = \frac{1}{\sqrt{n-1}} v_1
	\]
	
	Eigenspace attached to $-\sqrt{n-1}$
	\[
	E_{-\sqrt{n-1}} = \{(v_1, \dots, v_n)\in \CC^n : v_2 = \dots = v_n = \frac{1}{-\sqrt{n-1}} v_1
	\]
\end{soln}

\begin{example}[Final Exam 2018]
	Let $V$ be an inner product space over $\RR$ of dimension $n$. Show that there exists an isomorphism $f: V \rightarrow \RR^n$, such that $<v, v'> = f(v)\cdot f(v')$
\end{example}

\begin{soln}
	Let $\{v_1, \dots, v_n\}$ be an orthonormal basis of $V$.
	
	Let $\{e_1, \dots, e_n\}$ be the standard basis of $\RR^n$.
	
	Consider $f: V \rightarrow \RR^n$, $f(v) = [v]_B$. From theorem, we know that $f$ is an isomorphism.
	
	\[
	<v, v'> = [v]_b[v']_B (Assignment) = f(v)\cdot f(v')
	\]
	
	From assignment, given an orthonormal basis, then the inner product of two vectors is the product of the coordinates.
\end{soln}

\section{Tutorial 2}

\begin{theorem}[Spectral Theorem for symmetric real matrices]
	Let $A \in M_n(\RR)$ be a symmetric matrix. (ie $A = A^T$)
	
	Then, $A$ is diagonalizable over $\RR$
	
\end{theorem}

\begin{definition}
	A matrix $A \in M_n(\FF)$ is diagonalizable if $\exists P \in GL_n(\RR)$ and a diagonal matrix $D \in M_n(\RR)$ such that 
	\[
	A = PDP^{-1}
	\]
\end{definition}

\begin{example}[Diagonalizable matrix]
	\begin{enumerate}
		\ii
		Any diagonal matrix $D \in M_n(\RR)$ is diagonalizable
		\ii
		Any symmetric matrix $A \in M_n(\RR)$ is diagonalizable
		\ii
		Any matrix $A \in M_n(\RR)$ with $n$ distinct eigenvalues (Converse is not true)
	\end{enumerate}
\end{example}

\begin{theorem}
	If $A \in M_n(\FF)$ is diagonalizable, then there exists a orthonormal basis of $\FF^n$ consisting of eigenvectors of $A$
\end{theorem}

\begin{theorem}
	If $A \in M_n(\RR)$ is symmetric, then there exists a basis of $\RR^n$ consisting of eigenvectors of $A$.
\end{theorem}

Every single linear algebra exam has a question about diagonalizing a matrix.(Be comfortable with computing)

\begin{example}
	Let 
	\begin{align*}
	A = 
	\begin{bmatrix}
	1 & 2 & 0\\
	0 & 3 & 0\\
	2 & -4 & 2
	\end{bmatrix}
	\end{align*}
\end{example}

\begin{soln}
	\[
	\Delta_A(x) = det(xI_3 - A) = 
	\begin{bmatrix}
	x-1 & 2 & 0\\
	0 & x-3 & 0\\
	2 & -4 & x-2
	\end{bmatrix}
	= (x-1)(x-2)(x-3)
	\]
	
	Since we have 3 distinct eigenvalues, $A$ is diagonalizable over $\RR$.
	Eigenvalues:
	\begin{align*}
	\lambda_1 = 1 \text{   } \lambda_2 = 2 \text{   } \lambda_3 = 3
	\end{align*}
	
	Now we want to find a matrix $P$ such that $A = PDP^{-1}$
	
	Eigenvectors of distinct eigenvalues are linearly independent.
	
	Eigenvector for $\lambda_1 = 1$
	
	We find $v \in \RR^3$ such that $(I_3 - A)v = 0_{\RR}$
	\begin{align*}
		(I-A)
		\begin{bmatrix}
			v_1\\
			v_2\\
			v_3
		\end{bmatrix} = 
		\begin{bmatrix}
			0\\
			0\\
			0
		\end{bmatrix}
		\\
		\begin{bmatrix}
			0 & -2 & 0\\
			0 & -2 & 0\\
			-2 & 4 & -1
		\end{bmatrix}
		\begin{bmatrix}
			v_1\\
			v_2\\
			v_3
		\end{bmatrix} = 
		\begin{bmatrix}
			0\\
			0\\
			0
		\end{bmatrix}\\
		\implies -2v_2 = 0\\
		\implies -2v_2 = 0\\
		\implies -2v_1+4v_2-v_3 = 0\\
		\therefore v_2 = 0\\
		v_3 = -2v_1
	\end{align*}
	\[
	E_1 = \left\{(v_1, 0, -2v_1): v \in \RR\right\} = span\left\{1, 0, -2\right\}
	\]
	Eigenvector for $\lambda_2=2$ We find $E_2$
\end{soln}
\end{document}
